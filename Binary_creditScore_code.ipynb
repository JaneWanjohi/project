{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "quality-puzzle",
   "metadata": {},
   "source": [
    "# Binary Class Credit score Prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-surrey",
   "metadata": {},
   "source": [
    "person_age -\tAge\n",
    "\n",
    "person_income -\tAnnual Income\n",
    "\n",
    "person_home_ownershipHome ownership\n",
    "\n",
    "person_emp_length \tEmployment length (in years)\n",
    "\n",
    "loan_intent \tLoan intent\n",
    "\n",
    "loan_grade \tLoan grade\n",
    "\n",
    "loan_amnt \tLoan amount\n",
    "\n",
    "loan_int_rate \tInterest rate\n",
    "\n",
    "loan_status \tLoan status (0 is non default 1 is default)\n",
    "\n",
    "loan_percent_income \tPercent income\n",
    "\n",
    "cb_person_default_on_file \tHistorical default\n",
    "\n",
    "cb_preson_cred_hist_length \tCredit history length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-alarm",
   "metadata": {},
   "source": [
    "**Import Libraries  and the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "connected-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import colorama\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "#sklearn package\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "##keras package\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "##lime package\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data\n",
    "df = pd.read_csv(\"credit_risk_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is does our data composed of\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the different categpries in each of the categorical variables \n",
    "\n",
    "print(Style.BRIGHT+ 'Summary of Credit Risk Data:' + Style.RESET_ALL)\n",
    "print(Style.BRIGHT+ '--------------------------' + Style.RESET_ALL)\n",
    "print(Fore.BLACK+ Style.BRIGHT+ 'person_home_ownership' + Style.RESET_ALL+'           :',\\\n",
    "      Fore.RED+ Style.BRIGHT+ str(4) + Style.RESET_ALL + ' (Rent, Own, Mortgage, Other )')\n",
    "print(Fore.BLACK+ Style.BRIGHT+ 'Loan_intent' + Style.RESET_ALL+'          :',\\\n",
    "      Fore.RED+ Style.BRIGHT+ str(6) + Style.RESET_ALL + ' (Personal, Education, Medical,Venture, Home Improvemnet, Debt Consolidation)')\n",
    "print(Fore.BLACK+ Style.BRIGHT+ 'loan_grade' + Style.RESET_ALL+'       :',\\\n",
    "      Fore.RED+ Style.BRIGHT+ str(7) + Style.RESET_ALL + ' (A, B, C, D, E, F, G)')\n",
    "print(Fore.BLACK+ Style.BRIGHT+ 'cb_person_default_on_file' + Style.RESET_ALL+'        :',\\\n",
    "      Fore.RED+ Style.BRIGHT+ str(2) + Style.RESET_ALL + ' (Y, N)')\n",
    "print(Fore.BLACK+ Style.BRIGHT+ 'Loan_Status' + Style.RESET_ALL+'      :',\\\n",
    "      Fore.RED+ Style.BRIGHT+ str(2) + Style.RESET_ALL + ' (1, 0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated = df.duplicated()\n",
    "df[duplicated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"person_age==23 & person_income==42000 &\\\n",
    "person_home_ownership=='RENT'& loan_int_rate==9.99\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use correlation to check collinearity\n",
    "cor = df_new.corr(method='spearman')\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.heatmap(cor, cmap=plt.cm.winter_r,annot=True)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-scope",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x ='person_home_ownership', hue='loan_status',data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, y=\"loan_intent\", hue=\"loan_status\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x ='cb_person_default_on_file', hue='loan_status',data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x ='loan_grade', hue='loan_status',data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the variables with a high correlation of more than 0.8\n",
    "df_new = df_new.drop(['person_age'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the categorical variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in df_new.columns:\n",
    "    if df_new[col].dtype == 'object':\n",
    "        df_new[col] = le.fit_transform(df_new[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define an estimator\n",
    "lr = LinearRegression()\n",
    "imp = IterativeImputer(estimator=lr, verbose=2, max_iter=30, tol=1e-10, imputation_order='roman')\n",
    "\n",
    "#imputer = IterativeImputer(random_state=100, max_iter=10)\n",
    "K = imp.fit_transform(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "K1 = pd.DataFrame(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = {i:df_new.columns[i] for i in range(len(list(df_new.columns)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "K1.rename(columns=col_names, inplace=True)\n",
    "df_new = K1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-banana",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide the data into input matrix and output separately\n",
    "X = df_new.drop(['loan_status'], axis=1)\n",
    "y= df_new['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for similarity in these three variables\n",
    "X[['person_income', 'loan_amnt', 'loan_percent_income']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop('loan_percent_income', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use RFECV for feature selection\n",
    "\n",
    "# Create a decision tree classifier\n",
    "estimator = DecisionTreeClassifier()\n",
    "  \n",
    "# find the optimal number of features\n",
    "selector = RFECV(estimator, cv=5)\n",
    "selector = selector.fit(X, y)\n",
    "  \n",
    "# Print the optimal number of features\n",
    "print(\"Optimal number of features: %d\" % selector.n_features_)\n",
    "  \n",
    "# Print the selected features\n",
    "print(\"Selected features: %s\" % selector.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_rfecv = X.columns[selector.support_].tolist()\n",
    "select_rfecv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    " #drop the irrelevant features not chosen by the classifier\n",
    "X_new = X.drop(['cb_person_default_on_file'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define standard scaler\n",
    "scaler = StandardScaler()\n",
    "  \n",
    "# transform data\n",
    "X_scaled = scaler.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-decimal",
   "metadata": {},
   "source": [
    "**Splitting the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state=0)\n",
    "len(x_train), len(y_train), len(x_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts().plot.pie(autopct='%1.1f%%', textprops ={'fontsize':10})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to balance the training set\n",
    "#counter is used to count the values\n",
    "counter = Counter(y_train)\n",
    "print('Before', counter)\n",
    "\n",
    "#define smote\n",
    "smt = SMOTE()\n",
    "X_train_smt, y_train_smt = smt.fit_resample(x_train, y_train)\n",
    "counter = Counter(y_train_smt)\n",
    "print('After', counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-modeling",
   "metadata": {},
   "source": [
    "**Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a logistic regression model\n",
    "#before balancing the data\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-worcester",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after balancing the data\n",
    "logreg_smt = LogisticRegression()\n",
    "logreg_smt.fit(X_train_smt, y_train_smt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models prediction\n",
    "pred_y = model.predict(x_test)\n",
    "y_pred_smt = logreg_smt.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, pred_y)\n",
    "\n",
    "#print(cf_matrix)\n",
    "ax = sns.heatmap(cf_matrix, annot=True,fmt='d', cmap='Blues')\n",
    "\n",
    "# set x-axis label and ticks. \n",
    "ax.set_xlabel(\"Predicted Value\", fontsize=14, labelpad=20)\n",
    "ax.xaxis.set_ticklabels(['non defaulter', 'defaulter'])\n",
    "\n",
    "# set y-axis label and ticks\n",
    "ax.set_ylabel(\"Actual Value\", fontsize=14, labelpad=20)\n",
    "ax.yaxis.set_ticklabels(['non defaulter', 'defaulter'])\n",
    "\n",
    "# set plot title\n",
    "ax.set_title(\"Confusion Matrix Before Balancing\", fontsize=14, pad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the classification report before balancing the data\n",
    "report = classification_report(y_test, pred_y)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting confusionmatrix after balancing the data\n",
    "#Get the confusion matrix\n",
    "cf_matrixb = confusion_matrix(y_test, y_pred_smt)\n",
    "#print(cf_matrix)\n",
    "ax1 = sns.heatmap(cf_matrixb, annot=True,fmt='d', cmap='Blues')\n",
    "# set x-axis label and ticks. \n",
    "ax1.set_xlabel(\"Predicted Value\", fontsize=14, labelpad=20)\n",
    "ax1.xaxis.set_ticklabels(['non defaulter', 'defaulter'])\n",
    "\n",
    "# set y-axis label and ticks\n",
    "ax1.set_ylabel(\"Actual Value\", fontsize=14, labelpad=20)\n",
    "ax1.yaxis.set_ticklabels(['non defaulter', 'defaulter'])\n",
    "\n",
    "# set plot title\n",
    "ax1.set_title(\"Confusion Matrix After Balancing\", fontsize=14, pad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the classification report of after data balancing\n",
    "report = classification_report(y_test, y_pred_smt)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need other metrices which are not in the classification report\n",
    "\n",
    "print(f\"Balanced Accuracy of the unbalanced data is: {balanced_accuracy_score(y_test, pred_y)}\")\n",
    "print(f\"Balanced Accuracy of the balanced data is: {balanced_accuracy_score(y_test, y_pred_smt)}\")\n",
    "\n",
    "print(f\"AUC-ROC Score of the unbalanced data is: {roc_auc_score(y_test, pred_y)}\")\n",
    "print(f\"AUC-ROC Score of the balanced data is: {roc_auc_score(y_test, y_pred_smt)}\")\n",
    "\n",
    "print(f\"Matthews Coefficient of the unbalanced data is: {matthews_corrcoef(y_test, pred_y)}\")\n",
    "print(f\"Matthews Coefficient of the balanced data is: {matthews_corrcoef(y_test, y_pred_smt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "pred_prob1 = model.predict_proba(x_test)\n",
    "pred_prob2 = logreg_smt.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc scores\n",
    "auc_score1 = roc_auc_score(y_test, pred_prob1[:,1])\n",
    "auc_score2 = roc_auc_score(y_test, pred_prob2[:,1])\n",
    "\n",
    "print(auc_score1, auc_score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-membrane",
   "metadata": {},
   "source": [
    "**Multilayer Perceptron**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to convert the values to categorical\n",
    "y_train1 = to_categorical(y_train)\n",
    "y_train_smt1 = to_categorical(y_train_smt)\n",
    "y_test1 = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(units=8, activation='relu', input_dim=x_train.shape[1]))\n",
    "model_1.add(layers.Dropout(0.1))\n",
    "model_1.add(Dense(units=6, activation='relu' ))\n",
    "model_1.add(layers.Dropout(0.1))\n",
    "model_1.add(Dense(units=2, activation='sigmoid'))\n",
    "model_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "history = model_1.fit(x_train, y_train1, validation_split=0.2, epochs=50, batch_size=132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model after balancing the data\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(units=8, activation='relu', input_dim=x_train.shape[1]))\n",
    "model_2.add(layers.Dropout(0.1))\n",
    "model_2.add(Dense(units=6, activation='relu' ))\n",
    "model_2.add(layers.Dropout(0.1))\n",
    "model_2.add(Dense(units=2, activation='sigmoid'))\n",
    "model_2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model_2.fit(X_train_smt, y_train_smt1,validation_split=0.2, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-uruguay",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "loss, accuracy = model_1.evaluate(x_test, y_test1)\n",
    " \n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "loss, accuracy2 = model_2.evaluate(x_test, y_test1)\n",
    " \n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on test dataset\n",
    "pred_y = model_1.predict(x_test)\n",
    "pred_y2 = model_2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y1= np.argmax(pred_y, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test1, axis=1)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y2= np.argmax(pred_y2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true, pred_y1)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, pred_y1)\n",
    "#print(cf_matrix)\n",
    "ax = sns.heatmap(cf_matrix, annot=True,fmt='d', cmap='Blues')\n",
    "# set x-axis label and ticks. \n",
    "ax.set_xlabel(\"Predicted Value\", fontsize=14, labelpad=20)\n",
    "ax.xaxis.set_ticklabels(['non defaulter', 'defaulter'])\n",
    "\n",
    "# set y-axis label and ticks\n",
    "ax.set_ylabel(\"Actual Value\", fontsize=14, labelpad=20)\n",
    "ax.yaxis.set_ticklabels(['non defaulter', 'defaulter'])\n",
    "\n",
    "# set plot title\n",
    "ax.set_title(\"Confusion Matrix Before Balancing\", fontsize=14, pad=20)\n",
    "#plt.savefig('ConMat_nn1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true, pred_y2)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, pred_y2)\n",
    "#print(cf_matrix)\n",
    "ax = sns.heatmap(cf_matrix, annot=True,fmt='d', cmap='Blues')\n",
    "# set x-axis label and ticks. \n",
    "ax.set_xlabel(\"Predicted Value\", fontsize=14, labelpad=20)\n",
    "ax.xaxis.set_ticklabels(['non defaulter', 'defaulter'])\n",
    "\n",
    "# set y-axis label and ticks\n",
    "ax.set_ylabel(\"Actual Value\", fontsize=14, labelpad=20)\n",
    "ax.yaxis.set_ticklabels(['non defaulter', 'defaulter'])\n",
    "\n",
    "# set plot title\n",
    "ax.set_title(\"Confusion Matrix After Balancing\", fontsize=14, pad=20)\n",
    "#plt.savefig('ConMat_nn2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy of the unbalanced data is: {accuracy_score(y_true, pred_y1)}\")\n",
    "print(f\"Accuracy of the balanced data is: {accuracy_score(y_true, pred_y2)}\")\n",
    "\n",
    "print(f\"Balanced Accuracy of the unbalanced data is: {balanced_accuracy_score(y_true, pred_y1)}\")\n",
    "print(f\"Balanced Accuracy of the balanced data is: {balanced_accuracy_score(y_true, pred_y2)}\")\n",
    "\n",
    "print(f\"Matthews Coefficient of the unbalanced data is: {matthews_corrcoef(y_true, pred_y1)}\")\n",
    "print(f\"Matthews Coefficient of the balanced data is: {matthews_corrcoef(y_true, pred_y2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-signal",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc1 = roc_auc_score(y_true, pred_y1)\n",
    "roc2 = roc_auc_score(y_true, pred_y2)\n",
    "roc1, roc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_new.columns\n",
    "# Obtain the feature importances\n",
    "importances = np.sum(np.abs(model_1.get_weights()[0]), axis=1)\n",
    "\n",
    "# Sort the feature importances in descending order and get the corresponding feature names\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "sorted_importances = importances[sorted_indices]\n",
    "sorted_feature_names = [feature_names[i] for i in sorted_indices]\n",
    "\n",
    "# Create a horizontal bar plot of the feature importances\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(range(len(sorted_importances)), sorted_importances, tick_label=sorted_feature_names)\n",
    "ax.set_xlabel('Feature Importance')\n",
    "ax.set_ylabel('Feature')\n",
    "plt.title('Feature on Imbalanced data')\n",
    "plt.savefig('feature imp b_n1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_new.columns\n",
    "# Obtain the feature importances\n",
    "importances = np.sum(np.abs(model_2.get_weights()[0]), axis=1)\n",
    "\n",
    "# Sort the feature importances in descending order and get the corresponding feature names\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "sorted_importances = importances[sorted_indices]\n",
    "sorted_feature_names = [feature_names[i] for i in sorted_indices]\n",
    "\n",
    "# Create a horizontal bar plot of the feature importances\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(range(len(sorted_importances)), sorted_importances, tick_label=sorted_feature_names)\n",
    "ax.set_xlabel('Feature Importance')\n",
    "ax.set_ylabel('Feature')\n",
    "plt.title('Feature on MLP')\n",
    "plt.savefig('feature imp b_n2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model as a pickle string.\n",
    "#saved_model_n1 = pickle.dumps(model_1)\n",
    "#saved_model_n2 = pickle.dumps(model_2)\n",
    "\n",
    "# Load the pickled model\n",
    "#load_model1 = pickle.loads(saved_model)\n",
    "  \n",
    "# Use the loaded pickled model to make predictions\n",
    "#load_model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-channel",
   "metadata": {},
   "source": [
    "**LIME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_new, y, test_size = 0.2, random_state=0)\n",
    "len(x_train), len(y_train), len(x_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(y_train)\n",
    "print('Before', counter)\n",
    "\n",
    "smt = SMOTE()\n",
    "X_train_smt, y_train_smt = smt.fit_resample(x_train, y_train)\n",
    "counter = Counter(y_train_smt)\n",
    "print('After', counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imbalanced data\n",
    "explainer = lime_tabular.LimeTabularExplainer(\n",
    "    training_data=np.array(x_train),\n",
    "    feature_names=x_train.columns,\n",
    "    class_names=['non defaulter', 'defaulter'],\n",
    "    mode='classification'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(\n",
    "    data_row=x_test.iloc[4], \n",
    "    predict_fn=model_1.predict\n",
    "    \n",
    ")\n",
    "\n",
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "#balanced data\n",
    "explainer1 = lime_tabular.LimeTabularExplainer(\n",
    "    training_data=np.array(X_train_smt),\n",
    "    feature_names=X_train_smt.columns,\n",
    "    class_names=['non defaulter', 'defaulter'],\n",
    "    mode='classification'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer1.explain_instance(\n",
    "    data_row=x_test.iloc[4], \n",
    "    predict_fn=model_2.predict\n",
    ")\n",
    "\n",
    "exp.show_in_notebook(show_table=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
